Question 1
============

1
---
We need to modulate a wave in order to use it to encode data.
We can modulate data in a way such that smaller antennas can be used, which is very nice for mobile stations.


2
---
In Amplitude Shift Keying (ASK) we modify the amplitude of a wave to encode bits. For instance, we could encode a 1 as sending a fixed-size wave for T time, and a 0 as sending nothing for T time.

In Phase Shift Keying (PSK) we modify the phase of a wave to encode bits. For instance, we could encode a 1 with a phase starting at the top of a wave and a 0 with a phase starting at the bottom of a wave.

In Frequency Shify Keying (FSK) we modify the frequency of a wave to encode bits. For instance, we could encode a 1 by sending at one rate, and a 0 by sending at half the rate of a 1.

3
---
Noise and interference has a smaller impact.
More resistant to multipath propagation.

4
---

5
---


Question 2
============

1
---
802.11 uses CSMA/CA. Collision detection is performed by the sender. Because of the hidden terminal problem, the sender might not see the same signals as the receiver, which means that it isn't possible for the sender to detect collisions, thereby making collision detection infeasible. The exposed terminal problem also causes problems w.r.t. using CD since a sender could detect collisions which aren't interfering with his own transmission, meaning he wouldn't transmit even though he "should".


2
---
Yes, RTS/CTS helps against the hidden terminal problems.
It helps because the receiver, whom it is assumed can be heard by everybody, announces who is allowed to send to him. This has the effect that everyone who might send to the receiver will receive the CTS, letting them know not to transmit to him again until the size described in the CTS has had time to be transmitted.

3
---
Yes, RTS/CTS helps against the exposed terminal problem as well.
Assume that B and C want to send data to A and D, respectively. A is not in range of C, and D is not in range of B. This means that both B and C can transmit their data without interfering with each other's transmission.

    A <- B    C -> D

C will overhear B sending an RTS to A, but not hear A's CTS. From this, C can infer that he is not in range of A, meaning that he can safely transmit to D. This assumes symmetric transmission distance between A and C.


4
---
The residual backoff timer is used as a fairness-mechanism.
When terminals detect an ongoing transmission on the shared media, they have to wait for a fixed interval (DIFS) plus a random amount of time before again sensing the media. In order to make the waiting more fair, i.e. the longer a terminal has waited the more likely it is to get to use the media, the terminals don't pick a new random time whenever the medium is busy, but "work on" the same timer until it expires. It is important to note that the residual backoff timer is stopped when the media is used by another terminal.

Question 3
============

1
---
Assuming that we want to promise a certain quality of each phone call (i.e. a minimum bandwidth), I'd pick fixed TDMA. Using fixed TDMA we can promise all users the same bandwidth. This solution is not very bandwidth efficient if only a few users are using it, but on the other hand the quality of service of this system would not degrade as the number of users reaches the maximum because there is no contention for slots. Once the maximum is reached there can be no more users on the system since the bandwidth would be fully utilized, and there would be no more free time slots.

2
---
Besides polled TDMA generally being used in Bluetooth, it has two variations hereof: Synchronous Connection Oriented (SCO) and Asynchronous Connection Less (ACL).

In SCO, a certain bandwidth is reserved for a slave. The master will poll the slave at a rate giving him the reserved bandwidth.
In ACL, the master polls terminals in a round-robin fashion, asking them for the amount of data they want to transfer. The slaves may request to send up to 5 slots worth of data.

Because of the promised quality of service that SCO can deliver, it is most often used for voice, while ACL is more often used for transferring files.

3
---
B-MAC sends a very large preamble before each packet (about the time of a sleep-cycle), in order to make sure that possible receivers are awake and aware of the coming data transmission. If there isn't a lot of payload to be transmitted, the preamble might make up a substantial part of the total data transmitted. This means that a substantial time (and power) is spent sending "unnecessary" data, yielding a low payload-to-power ratio.


Question 4
============

1
---
Because signal strengths can vary a lot within a relatively short distance and time, a handover point could trigger continuous handovers between base stations. Because handovers take time, the quality of ongoing communications might degrade to the point of being unusable.

2
---
Yes, they can be used. The codes are orthogonal, meaning that neither is part of the other.

3
---
~~~~~
                      00000000
                0000
             /        00001111
            /
        00
      /     \
     /       \        00110011
    /          0011
   /                  00111100
0
   \                  01010101
    \           0101
     \       /        01011010
      \     /
        01
            \
             \        01100110
                0110
                      01101001
~~~~~

Such codes could be: (0110, 0101, 00000000, 00001111, 00110011, 00111100)


4
---
The term is used to describe the amount of locations that a network operator uses his available channels.

5
---
A high reuse factor gives the operator a high system capacity, meaning that he can serve more customers simultaneously. A high reuse factor could lead to higher interference, while it also adds more robustness to the network since there is going to be more base stations.
A high reuse factor is probably going to be more expensive to implement, as many more base stations are required.
Mobile stations will use less power because they are closer to the base stations.

A low reuse factor gives the operator a lower system capacity, meaning that he can serve fewer customers simultaneously. It is cheaper to implement because few base stations are required. Mobile stations will use more power, because they are further away from base stations.


Question 5
============

1
---
Yes. In the case where two mobile nodes have the same FA, it is quite possible that they share their CoA; the IP address of the FA. Since traffic is IP-in-IP tunneled, the FA can correctly route packets to each mobile node.

2
---
This is a problem in wireless networks because they are much more lossy than wired connections. Packet loss in wired connections can (somewhat) safely be attributed to congestion. This is not the case in wireless, where packets are much more likely to drop when there's no congestion.

Question 6
============

1
---
A datacenter could load balance on layer 3, for instance hashing on TCP-connection tuples (src, src_port). A disadvantage of this is that a request from a specific src can be mapped to only ~65K different servers.
A layer 7 load balancer will use data form the application layer. If we take HTTP as an example, the load balancer can balance traffic based on contents from the HTTP header: host, URL, cookies, etc. It is common to hash on these values, in order to assign requests to clusters of servers, or directly to specific servers.

A data center could also do round-robin load balancing, simply letting servers take turn to respond to a request. In this case each server has to have (access to) the same content in order to respond to a request. Using a layer 4-7 load balancer, the request can be split in to different subrequests, each subrequest sent to a highly specialized server, serving only static content, dynamic, etc.


2
---

Time progresses downwards.
~~~~~
 Client                  Switch               Server(s)               SEQNR SRC
--------                --------             -----------             -----------
  TCP(SYN) ------------->                                                X
           <----------- TCP(SYN,ACK)                                     X
  TCP(ACK) ------------->                                                X + 1
  TCP(HTTP(GET)) ------->                                                X + 1 + HTTP
                        TCP(SYN) ----------------->                      Y
                                 <--------------- TCP(SYN,ACK)           Y
                        TCP(ACK) ----------------->                      Y + 1
                        TCP(HTTP(GET)) ----------->                      Y + 1 + HTTP
                                 <--------------- TCP(HTTP(200 OK))      Y + 1 + HTTP
          <------------ TCP(HTTP(200 OK))                                X + 1 + HTTP

~~~~~


Question 7
============

1
---
That depends on the topology of the network and the oversubscription rate at each level of the network.
The bisection bandwidth of a network is the bandwidth that can be attained between the two parts of the network, when it's split in to two equally large parts (w.r.t. the number of servers). The bisection bandwidth most often is used to describe the worst case, i.e. the bisection with the lowest bandwidth.

2
---
The oversubscription rate of a specific switch would then be $\frac{upwards links}{downwards links}$, upwards being the direction of the Internet, downwards being the direction of the servers.

3
---
The oversubscription rate at each level is 1:1. Because of the way the switches are connected, all pairs of nodes can fully utilize their links simultaneously in a bisection of the network, yielding full bisection bandwidth.

4
---
- VMs don't have to change their IP address upon migration.
- Only minimal configuration of network equipment is required, making it easy to incrementally add switches/nodes to network.

5
---
- Major state in switches.
- Broadcast packets have major impact on network.
- Spanning tree algorithm:
    - Utilizes only one path in network => redundant paths are unnecessary unless a path fails.
    - Takes time to rebuild spanning tree on path failure.

Question 8
============

1
---
TCP incast is a problem that arises in the partition/aggregate structure. When an aggregator receives responses from a lot of worker nodes at the same time, the buffers of a switch on the way to the aggregator might overflow because of the sudden burst in packes. This means that packets might be lost, maybe causing TCP to go in to slow-start. Since TCP waits at least RTO time before retransmitting, this can cause a huge delay on transmissions.

DCTCP makes use of TCPs ECN (Explicit Congestion Control) mechanism, letting the sender adjust his transmission rate before buffers become full at the switches. This empties up the buffers such that they can be used during bursty loads, such as during TCP incast.

2
---
RDMA effectively removes the OS from the data path, meaning that the OS is not involved during transferral of data. The OS is only involved in control messages (connection set up and tear down). This is not the case for socket-based networking, where the OS has to do multiplexing on layer 4.

3
---
Otherwise the memory might be swapped out, being replaced by the memory of another process. Neither the RDMA sender or the other process whose memory might be swapped in is interested in this happening.

Question 9
============

1
---
- Network OS and controllers of that OS
- Common programmable interface to the switches
- Logically centralized authority in charge of distributing rules to switches

2
---
Amy could set up a FlowVisor controller which directs traffic from A to B (based on in/egress ports and/or MAC addresses and/or IP addresses) to a controller she's in charge of, implementing her Amy-OPSF protocol, and lets the switches do whatever else they were otherwise supposed to do with the rest of the traffic.

3
---
Load balancing flows on multiple paths between hosts can increase the usable bandwidth between the hosts.
The VL2 system load balances traffic in a Fat Tree network using some tricks at the IP level, also load balancing using ECMP.

Multipath TCP (MPTCP) can be used, for instance in VL2, to load balance a logical TCP flow over multiple paths in the network (if the network supports it.)